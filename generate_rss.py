import os
import re
from datetime import datetime
from xml.etree import ElementTree as ET
from xml.dom import minidom

# ---------------------- é…ç½®é¡¹ï¼ˆåªæ”¹è¿™2å¤„ï¼ï¼‰----------------------
GITHUB_USERNAME = "L-030119"  # æ”¹ï¼šæ¯”å¦‚ä½ çš„è´¦å·æ˜¯abc123ï¼Œå°±å¡«"abc123"
REPO_NAME = "my-private-rss"            # æ”¹ï¼šä½ çš„ä»“åº“åï¼ˆæˆªå›¾é‡Œæ˜¯my-private-rssï¼Œä¸ç”¨åŠ¨ï¼‰
ARTICLES_FOLDER = "articles"         # ä¸ç”¨æ”¹
RSS_FILE_PATH = "my-rss.xml"         # ä¸ç”¨æ”¹
# -------------------------------------------------------------

# æ ¼å¼åŒ–XMLï¼ˆè®©ç”Ÿæˆçš„XMLæ›´æ˜“è¯»ï¼‰
def prettify_xml(elem):
    rough_string = ET.tostring(elem, 'utf-8')
    reparsed = minidom.parseString(rough_string)
    return reparsed.toprettyxml(indent="  ", encoding="UTF-8").decode("utf-8")

# ä»mdæ–‡ä»¶å/å†…å®¹æå–ä¿¡æ¯
def get_article_info(md_file_path):
    # 1. æå–æ–‡ä»¶åä¸­çš„æ—¥æœŸå’Œæ ‡é¢˜ï¼ˆæ¯”å¦‚ï¼š20251217_æ–‡ç« 1.md â†’ æ—¥æœŸ2025-12-17ï¼Œæ ‡é¢˜æ–‡ç« 1ï¼‰
    file_name = os.path.basename(md_file_path)
    date_str = re.findall(r"(\d{8})", file_name)
    title = re.sub(r"\d{8}_|\.md", "", file_name)
    
    # 2. è¯»å–mdæ–‡ä»¶å†…å®¹
    with open(md_file_path, "r", encoding="utf-8") as f:
        content = f.read().strip()
    
    # 3. ç”Ÿæˆå‘å¸ƒæ—¶é—´ï¼ˆRFC822æ ¼å¼ï¼ŒObsidian RSSæ’ä»¶è¯†åˆ«ï¼‰
    if date_str:
        date = datetime.strptime(date_str[0], "%Y%m%d")
        pub_date = date.strftime("%a, %d %b %Y 12:00:00 GMT")  # å›ºå®šæ—¶é—´12ç‚¹ï¼Œå¯æ”¹
    else:
        pub_date = datetime.now().strftime("%a, %d %b %Y 12:00:00 GMT")
    
    # 4. ç”Ÿæˆæ–‡ç« çš„Rawåœ°å€ï¼ˆä¾›Obsidianç‚¹å‡»è®¿é—®ï¼‰
    raw_url = f"https://raw.githubusercontent.com/{GITHUB_USERNAME}/{REPO_NAME}/main/{ARTICLES_FOLDER}/{file_name}"
    
    # 5. ç”Ÿæˆæ‘˜è¦ï¼ˆå–å‰200å­—ï¼Œå¯æ”¹ï¼‰
    summary = content[:200] + "..." if len(content) > 200 else content
    
    return {
        "title": title,
        "content": content,
        "summary": summary,
        "pub_date": pub_date,
        "raw_url": raw_url,
        "guid": raw_url  # ç”¨Rawåœ°å€åšå”¯ä¸€æ ‡è¯†ï¼Œé¿å…é‡å¤æŠ“å–
    }

# ä¸»å‡½æ•°ï¼šç”ŸæˆRSSæ–‡ä»¶
def generate_rss():
    # 1. è¯»å–ç°æœ‰RSSæ¨¡æ¿
    tree = ET.parse(RSS_FILE_PATH)
    root = tree.getroot()
    channel = root.find("channel")
    
    # æ¸…ç©ºç°æœ‰<item>ï¼ˆé¿å…é‡å¤ï¼‰
    for item in channel.findall("item"):
        channel.remove(item)
    
    # 2. éå†articlesæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰mdæ–‡ä»¶
    md_files = [f for f in os.listdir(ARTICLES_FOLDER) if f.endswith(".md")]
    md_files.sort(reverse=True)  # æŒ‰æ–‡ä»¶åå€’åºï¼ˆæ–°æ–‡ç« åœ¨å‰ï¼‰
    
    for md_file in md_files:
        md_path = os.path.join(ARTICLES_FOLDER, md_file)
        info = get_article_info(md_path)
        
        # 3. ç”Ÿæˆ<item>èŠ‚ç‚¹
        item = ET.SubElement(channel, "item")
        
        title_elem = ET.SubElement(item, "title")
        title_elem.text = info["title"]
        
        link_elem = ET.SubElement(item, "link")
        link_elem.text = info["raw_url"]
        
        description_elem = ET.SubElement(item, "description")
        # ç”¨CDATAåŒ…è£¹å†…å®¹ï¼Œé¿å…XMLè§£æé”™è¯¯
        description_elem.text = ET.CDATA(f"""
            <p>æ‘˜è¦ï¼š{info["summary"]}</p>
            <p>å®Œæ•´å†…å®¹ï¼š<a href="{info["raw_url"]}">ç‚¹å‡»æŸ¥çœ‹</a></p>
            <hr>
            <pre>{info["content"]}</pre>
        """)
        
        pubdate_elem = ET.SubElement(item, "pubDate")
        pubdate_elem.text = info["pub_date"]
        
        guid_elem = ET.SubElement(item, "guid")
        guid_elem.text = info["guid"]
    
    # 4. ä¿å­˜æ ¼å¼åŒ–åçš„XML
    with open(RSS_FILE_PATH, "w", encoding="utf-8") as f:
        f.write(prettify_xml(root))
    
    print(f"âœ… RSSç”ŸæˆæˆåŠŸï¼å…±å¤„ç† {len(md_files)} ç¯‡æ–‡ç« ")

if __name__ == "__main__":
    # æ£€æŸ¥articlesæ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(ARTICLES_FOLDER):
        os.makedirs(ARTICLES_FOLDER)
        print(f"ğŸ“ å·²åˆ›å»º{ARTICLES_FOLDER}æ–‡ä»¶å¤¹ï¼Œè¯·å…ˆæ”¾å…¥mdæ–‡ç« ")
    else:
        generate_rss()
